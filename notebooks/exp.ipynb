{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patch Embeddings Shape: tensor([[ 0.0775, -1.9374,  0.9095,  0.9679, -0.4470, -2.1310,  1.3363, -0.1088,\n",
      "          0.9213, -0.6648,  1.3608, -0.3220, -0.2833, -0.4444,  0.1376,  0.6279]],\n",
      "       grad_fn=<SqueezeBackward1>) torch.Size([1, 16])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/baskar/Desktop/Research/time_series_llm/venv/lib/python3.12/site-packages/torch/nn/modules/instancenorm.py:115: UserWarning: input's size at dim=0 does not match num_features. You can silence this warning by not passing in num_features, which is not used because affine=False\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "\n",
    "class PatchReprogram(nn.Module):\n",
    "    def __init__(self, time_steps, patch_size):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(time_steps, patch_size)\n",
    "        self.norm = nn.InstanceNorm1d(patch_size)\n",
    "    \n",
    "    def forward(self, time_series_data):\n",
    "        \"\"\"\n",
    "        Input : (batch_size, time_steps)\n",
    "        Output : (batch_size, patch_size)\n",
    "        \"\"\"\n",
    "        patches = self.linear(time_series_data)\n",
    "        return self.norm(patches)\n",
    "# Example Usage\n",
    "if __name__ == \"__main__\":\n",
    "    data = torch.randn(1, 252)  # Fake stock data (252 trading days)\n",
    "    patcher = PatchReprogram(time_steps=252, patch_size=16)\n",
    "    patch_embeddings = patcher(data)\n",
    "    print(\"Patch Embeddings Shape:\", patch_embeddings, patch_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text Embedding Shape: torch.Size([1, 6, 2560])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "\n",
    "class LLMEmbedder(nn.Module):\n",
    "    def __init__(self, model_name = \"microsoft/phi-2\"):\n",
    "        super().__init__()\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        self.model = AutoModel.from_pretrained(model_name)\n",
    "        self.hidden_size = self.model.config.hidden_size\n",
    "    \n",
    "    def embed_data(self, data):\n",
    "        \"\"\"\n",
    "        Converts input data into LLM embeddings.\n",
    "        output - (batch_size, seq_len, hidden_size)\n",
    "        \"\"\"\n",
    "        self.tokenizer.pad_token = self.tokenizer.eos_token\n",
    "        inputs = self.tokenizer(data, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "        outputs = self.model(**inputs)\n",
    "        return outputs.last_hidden_state\n",
    "if __name__ == \"__main__\":\n",
    "    embedder = LLMEmbedder()\n",
    "    text_embedding = embedder.embed_data(\"Predict next stock price movement\")\n",
    "    print(\"Text Embedding Shape:\", text_embedding.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:01<00:00,  1.22it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 25\u001b[39m\n\u001b[32m     23\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m     24\u001b[39m     embedder = LLMEmbedder()\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m     text_embedding = \u001b[43membedder\u001b[49m\u001b[43m.\u001b[49m\u001b[43membed_data\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mPredict next stock price movement\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     26\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mText Embedding Shape:\u001b[39m\u001b[33m\"\u001b[39m, text_embedding.shape)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 18\u001b[39m, in \u001b[36mLLMEmbedder.embed_data\u001b[39m\u001b[34m(self, data)\u001b[39m\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34membed_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, data):\n\u001b[32m     14\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     15\u001b[39m \u001b[33;03m    Converts input data into LLM embeddings.\u001b[39;00m\n\u001b[32m     16\u001b[39m \u001b[33;03m    output - (batch_size, seq_len, hidden_size)\u001b[39;00m\n\u001b[32m     17\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m     inputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpt\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtruncation\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     19\u001b[39m     outputs = \u001b[38;5;28mself\u001b[39m.model(**inputs).last_hidden_state\n\u001b[32m     21\u001b[39m     reduced_embeddings = \u001b[38;5;28mself\u001b[39m.projection(outputs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Research/time_series_llm/venv/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:2877\u001b[39m, in \u001b[36mPreTrainedTokenizerBase.__call__\u001b[39m\u001b[34m(self, text, text_pair, text_target, text_pair_target, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, padding_side, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[39m\n\u001b[32m   2875\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._in_target_context_manager:\n\u001b[32m   2876\u001b[39m         \u001b[38;5;28mself\u001b[39m._switch_to_input_mode()\n\u001b[32m-> \u001b[39m\u001b[32m2877\u001b[39m     encodings = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_one\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext_pair\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtext_pair\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mall_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2878\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m text_target \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   2879\u001b[39m     \u001b[38;5;28mself\u001b[39m._switch_to_target_mode()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Research/time_series_llm/venv/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:2987\u001b[39m, in \u001b[36mPreTrainedTokenizerBase._call_one\u001b[39m\u001b[34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, padding_side, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, split_special_tokens, **kwargs)\u001b[39m\n\u001b[32m   2965\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.batch_encode_plus(\n\u001b[32m   2966\u001b[39m         batch_text_or_text_pairs=batch_text_or_text_pairs,\n\u001b[32m   2967\u001b[39m         add_special_tokens=add_special_tokens,\n\u001b[32m   (...)\u001b[39m\u001b[32m   2984\u001b[39m         **kwargs,\n\u001b[32m   2985\u001b[39m     )\n\u001b[32m   2986\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2987\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mencode_plus\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2988\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2989\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtext_pair\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtext_pair\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2990\u001b[39m \u001b[43m        \u001b[49m\u001b[43madd_special_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[43madd_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2991\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2992\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtruncation\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtruncation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2993\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2994\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstride\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2995\u001b[39m \u001b[43m        \u001b[49m\u001b[43mis_split_into_words\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_split_into_words\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2996\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2997\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpadding_side\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpadding_side\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2998\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2999\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3000\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3001\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3002\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3003\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3004\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_length\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3005\u001b[39m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3006\u001b[39m \u001b[43m        \u001b[49m\u001b[43msplit_special_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[43msplit_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3007\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3008\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Research/time_series_llm/venv/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:3054\u001b[39m, in \u001b[36mPreTrainedTokenizerBase.encode_plus\u001b[39m\u001b[34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, padding_side, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[39m\n\u001b[32m   3033\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   3034\u001b[39m \u001b[33;03mTokenize and prepare for the model a sequence or a pair of sequences.\u001b[39;00m\n\u001b[32m   3035\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   3050\u001b[39m \u001b[33;03m        method).\u001b[39;00m\n\u001b[32m   3051\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   3053\u001b[39m \u001b[38;5;66;03m# Backward compatibility for 'truncation_strategy', 'pad_to_max_length'\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m3054\u001b[39m padding_strategy, truncation_strategy, max_length, kwargs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_padding_truncation_strategies\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3055\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3056\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtruncation\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtruncation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3057\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3058\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3059\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3060\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3061\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3063\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._encode_plus(\n\u001b[32m   3064\u001b[39m     text=text,\n\u001b[32m   3065\u001b[39m     text_pair=text_pair,\n\u001b[32m   (...)\u001b[39m\u001b[32m   3083\u001b[39m     **kwargs,\n\u001b[32m   3084\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Research/time_series_llm/venv/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:2779\u001b[39m, in \u001b[36mPreTrainedTokenizerBase._get_padding_truncation_strategies\u001b[39m\u001b[34m(self, padding, truncation, max_length, pad_to_multiple_of, verbose, **kwargs)\u001b[39m\n\u001b[32m   2777\u001b[39m \u001b[38;5;66;03m# Test if we have a padding token\u001b[39;00m\n\u001b[32m   2778\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m padding_strategy != PaddingStrategy.DO_NOT_PAD \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mself\u001b[39m.pad_token \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.pad_token_id < \u001b[32m0\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m2779\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   2780\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mAsking to pad but the tokenizer does not have a padding token. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2781\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mPlease select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2782\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mor add a new pad token via `tokenizer.add_special_tokens(\u001b[39m\u001b[33m{\u001b[39m\u001b[33m'\u001b[39m\u001b[33mpad_token\u001b[39m\u001b[33m'\u001b[39m\u001b[33m: \u001b[39m\u001b[33m'\u001b[39m\u001b[33m[PAD]\u001b[39m\u001b[33m'\u001b[39m\u001b[33m})`.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2783\u001b[39m     )\n\u001b[32m   2785\u001b[39m \u001b[38;5;66;03m# Check that we will truncate to a multiple of pad_to_multiple_of if both are provided\u001b[39;00m\n\u001b[32m   2786\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m   2787\u001b[39m     truncation_strategy != TruncationStrategy.DO_NOT_TRUNCATE\n\u001b[32m   2788\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m padding_strategy != PaddingStrategy.DO_NOT_PAD\n\u001b[32m   (...)\u001b[39m\u001b[32m   2791\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m (max_length % pad_to_multiple_of != \u001b[32m0\u001b[39m)\n\u001b[32m   2792\u001b[39m ):\n",
      "\u001b[31mValueError\u001b[39m: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "\n",
    "class LLMEmbedder(nn.Module):\n",
    "    def __init__(self, model_name = \"microsoft/phi-2\", target_dim=768):\n",
    "        super().__init__()\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        self.model = AutoModel.from_pretrained(model_name)\n",
    "        self.hidden_size = self.model.config.hidden_size\n",
    "        self.projection = nn.Linear(self.hidden_size, target_dim)\n",
    "    \n",
    "    def embed_data(self, data):\n",
    "        \"\"\"\n",
    "        Converts input data into LLM embeddings.\n",
    "        output - (batch_size, seq_len, hidden_size)\n",
    "        \"\"\"\n",
    "        self.tokenizer.pad_token = self.tokenizer.eos_token\n",
    "        inputs = self.tokenizer(data, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "        outputs = self.model(**inputs).last_hidden_state\n",
    "\n",
    "        reduced_embeddings = self.projection(outputs)\n",
    "        return reduced_embeddings\n",
    "if __name__ == \"__main__\":\n",
    "    embedder = LLMEmbedder()\n",
    "    text_embedding = embedder.embed_data(\"Predict next stock price movement\")\n",
    "    print(\"Text Embedding Shape:\", text_embedding.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
