{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YF.download() has changed argument auto_adjust default to True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patched Data Shape: torch.Size([221, 30, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "class TimeSeriesProcessor:\n",
    "    def __init__(self, ticker, start, end, column=\"Close\"):\n",
    "        self.ticker = ticker\n",
    "        self.start = start\n",
    "        self.end = end\n",
    "        self.column = column\n",
    "        self.data = self._load_data()\n",
    "\n",
    "    def _load_data(self):\n",
    "        \"\"\"Fetch stock price data from Yahoo Finance.\"\"\"\n",
    "        df = yf.download(self.ticker, start=self.start, end=self.end)\n",
    "        return df[[self.column]].dropna().values  # Extract chosen column as numpy array\n",
    "\n",
    "    def instance_normalize(self):\n",
    "        \"\"\"Normalize time series data (zero mean, unit variance).\"\"\"\n",
    "        mean = np.mean(self.data, axis=0)\n",
    "        std = np.std(self.data, axis=0)\n",
    "        self.data = (self.data - mean) / (std + 1e-8)  # Prevent division by zero\n",
    "        return self\n",
    "\n",
    "    def create_patches(self, window_size=30, stride=1):\n",
    "        \"\"\"Create overlapping patches (time series windows).\"\"\"\n",
    "        patches = [\n",
    "            self.data[i : i + window_size] \n",
    "            for i in range(0, len(self.data) - window_size + 1, stride)\n",
    "        ]\n",
    "        return np.array(patches)\n",
    "\n",
    "# Usage Example\n",
    "if __name__ == \"__main__\":\n",
    "    processor = TimeSeriesProcessor(ticker=\"AAPL\", start=\"2023-01-01\", end=\"2024-01-01\")\n",
    "    processor.instance_normalize()\n",
    "    patches = processor.create_patches(window_size=30, stride=1)\n",
    "\n",
    "    # Convert to PyTorch tensor\n",
    "    patches_tensor = torch.tensor(patches, dtype=torch.float32)\n",
    "    print(\"Patched Data Shape:\", patches_tensor.shape)  # (num_patches, window_size, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patches Tensor Shape: torch.Size([221, 30])\n",
      "Patches Tensor Shape: torch.Size([221, 30])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:01<00:00,  1.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden size of model: 2560\n",
      "Fixed Word Embeddings Shape: torch.Size([5, 2560])\n",
      "Patches Tensor Shape: torch.Size([221, 30])\n",
      "Word Embeddings Shape: torch.Size([5, 2560])\n"
     ]
    },
    {
     "ename": "NotImplementedError",
     "evalue": "Module [TimeSeriesToLanguage] is missing the required \"forward\" function",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNotImplementedError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 127\u001b[39m\n\u001b[32m    125\u001b[39m \u001b[38;5;66;03m# Transform time series into language representation\u001b[39;00m\n\u001b[32m    126\u001b[39m model = TimeSeriesToLanguage(input_dim=\u001b[32m30\u001b[39m, embed_dim=\u001b[32m2560\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m127\u001b[39m language_representation = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpatches_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mword_embeddings\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    129\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mFinal Language Representation Shape:\u001b[39m\u001b[33m\"\u001b[39m, language_representation.shape)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Research/time_series_llm/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Research/time_series_llm/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Research/time_series_llm/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:397\u001b[39m, in \u001b[36m_forward_unimplemented\u001b[39m\u001b[34m(self, *input)\u001b[39m\n\u001b[32m    386\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_forward_unimplemented\u001b[39m(\u001b[38;5;28mself\u001b[39m, *\u001b[38;5;28minput\u001b[39m: Any) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    387\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Define the computation performed at every call.\u001b[39;00m\n\u001b[32m    388\u001b[39m \n\u001b[32m    389\u001b[39m \u001b[33;03m    Should be overridden by all subclasses.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    395\u001b[39m \u001b[33;03m        registered hooks while the latter silently ignores them.\u001b[39;00m\n\u001b[32m    396\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m397\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[32m    398\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mModule [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m).\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m] is missing the required \u001b[39m\u001b[33m\"\u001b[39m\u001b[33mforward\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m function\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    399\u001b[39m     )\n",
      "\u001b[31mNotImplementedError\u001b[39m: Module [TimeSeriesToLanguage] is missing the required \"forward\" function"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import yfinance as yf\n",
    "import numpy as np\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "\n",
    "# -------------------- Step 1: Data Preprocessing -------------------- #\n",
    "class TimeSeriesProcessor:\n",
    "    def __init__(self, ticker, start, end, column=\"Close\"):\n",
    "        self.ticker = ticker\n",
    "        self.start = start\n",
    "        self.end = end\n",
    "        self.column = column\n",
    "        self.data = self._load_data()\n",
    "\n",
    "    def _load_data(self):\n",
    "        df = yf.download(self.ticker, start=self.start, end=self.end)\n",
    "        return df[[self.column]].dropna().values\n",
    "\n",
    "    def instance_normalize(self):\n",
    "        mean = np.mean(self.data, axis=0)\n",
    "        std = np.std(self.data, axis=0)\n",
    "        self.data = (self.data - mean) / (std + 1e-8)\n",
    "        return self\n",
    "\n",
    "    def create_patches(self, window_size=30, stride=1):\n",
    "        patches = [\n",
    "            self.data[i : i + window_size] \n",
    "            for i in range(0, len(self.data) - window_size + 1, stride)\n",
    "        ]\n",
    "        return np.array(patches)\n",
    "\n",
    "# -------------------- Step 2: Patch Embedder -------------------- #\n",
    "class PatchEmbedder(nn.Module):\n",
    "    def __init__(self, window_size, embed_dim):\n",
    "        super().__init__()\n",
    "        self.projection = nn.Linear(window_size, embed_dim)  \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.squeeze(-1)  # Remove the last dimension -> (num_patches, window_size)\n",
    "        return self.projection(x)  # Output shape: (num_patches, embed_dim)\n",
    "\n",
    "\n",
    "\n",
    "# -------------------- Step 3: Phi-3 Word Embeddings -------------------- #\n",
    "class Phi3Embedder:\n",
    "    def __init__(self, model_name=\"microsoft/phi-2\"):\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        self.model = AutoModel.from_pretrained(model_name)\n",
    "\n",
    "    def get_word_embeddings(self, words):\n",
    "        self.tokenizer.pad_token = self.tokenizer.eos_token\n",
    "        inputs = self.tokenizer(words, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "        print(\"Hidden size of model:\", self.model.config.hidden_size)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(**inputs)  # Output is (batch_size, seq_len, hidden_dim)\n",
    "        \n",
    "        # Use CLS token (first token) OR mean pooling\n",
    "        cls_embeddings = outputs.last_hidden_state[:, 0, :]  # (batch_size, embedding_dim)\n",
    "\n",
    "        print(\"Fixed Word Embeddings Shape:\", cls_embeddings.shape)  # Debugging\n",
    "        return cls_embeddings  # Should now be (num_words, 256)\n",
    "\n",
    "\n",
    "# -------------------- Step 4: Multi-Head Attention Fusion -------------------- #\n",
    "class TimeSeriesToLanguage(nn.Module):\n",
    "    def __init__(self, input_dim, embed_dim, num_heads=4):\n",
    "        super().__init__()\n",
    "        self.patch_embedder = PatchEmbedder(input_dim, embed_dim)\n",
    "        self.text_linear = nn.Linear(embed_dim, embed_dim)\n",
    "        self.attention = nn.MultiheadAttention(embed_dim, num_heads)\n",
    "        self.output_linear = nn.Linear(embed_dim, embed_dim)\n",
    "\n",
    "    def forward(self, time_series_patches, text_embeddings):\n",
    "        time_series_embeddings = self.patch_embedder(time_series_patches)  \n",
    "        # Shape: (num_patches, embed_dim)\n",
    "\n",
    "        time_series_embeddings = time_series_embeddings.unsqueeze(1)  \n",
    "        # Shape: (num_patches, 1, embed_dim)\n",
    "\n",
    "        text_prototypes = self.text_linear(text_embeddings)  \n",
    "        # Shape: (num_words, embed_dim)\n",
    "\n",
    "        text_prototypes = text_prototypes.unsqueeze(1)  \n",
    "        # Shape: (num_words, 1, embed_dim)\n",
    "\n",
    "        # Ensure correct shape for MultiheadAttention\n",
    "        time_series_embeddings = time_series_embeddings.permute(1, 0, 2)  \n",
    "        # Shape: (1, num_patches, embed_dim)\n",
    "\n",
    "        text_prototypes = text_prototypes.permute(1, 0, 2)  \n",
    "        # Shape: (1, num_words, embed_dim)\n",
    "\n",
    "        # Ensure `seq_len` is the same for both\n",
    "        if time_series_embeddings.shape[1] != text_prototypes.shape[1]:\n",
    "            min_seq_len = min(time_series_embeddings.shape[1], text_prototypes.shape[1])\n",
    "            time_series_embeddings = time_series_embeddings[:, :min_seq_len, :]\n",
    "            text_prototypes = text_prototypes[:, :min_seq_len, :]\n",
    "\n",
    "        attn_output, _ = self.attention(time_series_embeddings, text_prototypes, text_prototypes)\n",
    "\n",
    "        return self.output_linear(attn_output.squeeze(0))  # (num_patches, embed_dim)\n",
    "\n",
    "\n",
    "# -------------------- Step 5: Execution -------------------- #\n",
    "if __name__ == \"__main__\":\n",
    "    # Load and process time series data\n",
    "    processor = TimeSeriesProcessor(ticker=\"AAPL\", start=\"2023-01-01\", end=\"2024-01-01\")\n",
    "    processor.instance_normalize()\n",
    "    patches = processor.create_patches(window_size=30, stride=1)\n",
    "    \n",
    "    # Convert to tensor (num_patches, window_size)\n",
    "    patches_tensor = torch.tensor(patches, dtype=torch.float32).squeeze(-1)\n",
    "    print(\"Patches Tensor Shape:\", patches_tensor.shape)\n",
    "    print(\"Patches Tensor Shape:\", patches_tensor.shape)  # Should be [221, 30]\n",
    "\n",
    "    # Get Phi-3 word embeddings\n",
    "    phi3 = Phi3Embedder()\n",
    "    words = [\"growth\", \"volatility\", \"trend\", \"seasonality\", \"market\"]\n",
    "    word_embeddings = phi3.get_word_embeddings(words)\n",
    "    print(\"Patches Tensor Shape:\", patches_tensor.shape)  # Should be [221, 30]\n",
    "    print(\"Word Embeddings Shape:\", word_embeddings.shape)  # Should be [5, 256]\n",
    "\n",
    "    # Transform time series into language representation\n",
    "    model = TimeSeriesToLanguage(input_dim=30, embed_dim=2560)\n",
    "    language_representation = model(patches_tensor, word_embeddings)\n",
    "\n",
    "    print(\"Final Language Representation Shape:\", language_representation.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
