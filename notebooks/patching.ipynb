{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import yfinance as yf\n",
    "import numpy as np\n",
    "from transformers import AutoModel, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the patches : (221, 30, 1)\n",
      "Patches Tensor Shape: torch.Size([221, 30])\n",
      "First five patches : tensor([[-2.7332, -2.6598, -2.7360, -2.4742, -2.4440, -2.4110, -2.2539, -2.2584,\n",
      "         -2.1816, -2.1144, -2.1560, -2.1525, -2.0045, -1.8201, -1.7393, -1.7774,\n",
      "         -1.6579, -1.5457, -1.7125, -1.6391, -1.5742, -1.2674, -1.0579, -1.2155,\n",
      "         -1.0493, -1.2047, -1.2645, -1.2434, -1.0815, -1.1186],\n",
      "        [-2.6598, -2.7360, -2.4742, -2.4440, -2.4110, -2.2539, -2.2584, -2.1816,\n",
      "         -2.1144, -2.1560, -2.1525, -2.0045, -1.8201, -1.7393, -1.7774, -1.6579,\n",
      "         -1.5457, -1.7125, -1.6391, -1.5742, -1.2674, -1.0579, -1.2155, -1.0493,\n",
      "         -1.2047, -1.2645, -1.2434, -1.0815, -1.1186, -0.9971],\n",
      "        [-2.7360, -2.4742, -2.4440, -2.4110, -2.2539, -2.2584, -2.1816, -2.1144,\n",
      "         -2.1560, -2.1525, -2.0045, -1.8201, -1.7393, -1.7774, -1.6579, -1.5457,\n",
      "         -1.7125, -1.6391, -1.5742, -1.2674, -1.0579, -1.2155, -1.0493, -1.2047,\n",
      "         -1.2645, -1.2434, -1.0815, -1.1186, -0.9971, -1.0895],\n",
      "        [-2.4742, -2.4440, -2.4110, -2.2539, -2.2584, -2.1816, -2.1144, -2.1560,\n",
      "         -2.1525, -2.0045, -1.8201, -1.7393, -1.7774, -1.6579, -1.5457, -1.7125,\n",
      "         -1.6391, -1.5742, -1.2674, -1.0579, -1.2155, -1.0493, -1.2047, -1.2645,\n",
      "         -1.2434, -1.0815, -1.1186, -0.9971, -1.0895, -1.1556],\n",
      "        [-2.4440, -2.4110, -2.2539, -2.2584, -2.1816, -2.1144, -2.1560, -2.1525,\n",
      "         -2.0045, -1.8201, -1.7393, -1.7774, -1.6579, -1.5457, -1.7125, -1.6391,\n",
      "         -1.5742, -1.2674, -1.0579, -1.2155, -1.0493, -1.2047, -1.2645, -1.2434,\n",
      "         -1.0815, -1.1186, -0.9971, -1.0895, -1.1556, -1.3877]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "class TimeSeriesProcessor:\n",
    "    def __init__(self, ticker, start, end, column=\"Close\"):\n",
    "        self.ticker = ticker\n",
    "        self.start = start\n",
    "        self.end = end\n",
    "        self.column = column\n",
    "        self.data = self._load_data()\n",
    "\n",
    "    def _load_data(self):\n",
    "        df = yf.download(self.ticker, start=self.start, end=self.end)\n",
    "        return df[[self.column]].dropna().values\n",
    "\n",
    "    def instance_normalize(self):\n",
    "        mean = np.mean(self.data, axis=0)\n",
    "        std = np.std(self.data, axis=0)\n",
    "        self.data = (self.data - mean) / (std + 1e-8)\n",
    "        return self\n",
    "\n",
    "    def create_patches(self, window_size=30, stride=1):\n",
    "        patches = [\n",
    "            self.data[i : i + window_size] \n",
    "            for i in range(0, len(self.data) - window_size + 1, stride)\n",
    "        ]\n",
    "        print(f\"Shape of the patches : {np.array(patches).shape}\")\n",
    "        return np.array(patches)\n",
    "    \n",
    "processor = TimeSeriesProcessor(ticker=\"AAPL\", start=\"2023-01-01\", end=\"2024-01-01\")\n",
    "processor.instance_normalize()\n",
    "patches = processor.create_patches(window_size=30, stride=1)\n",
    "patches_tensor = torch.tensor(patches, dtype=torch.float32).squeeze(-1)\n",
    "print(\"Patches Tensor Shape:\", patches_tensor.shape)\n",
    "print(f\"First five patches : {patches_tensor[:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PatchEmbedder(nn.Module):\n",
    "    def __init__(self, window_size, embed_dim):\n",
    "        super().__init__()\n",
    "        self.projection = nn.Linear(window_size, embed_dim)  \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.squeeze(-1)  # Remove the last dimension -> (num_patches, window_size)\n",
    "        return self.projection(x)  # Output shape: (num_patches, embed_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:01<00:00,  1.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden size of model: 2560\n",
      "Fixed Word Embeddings Shape: torch.Size([5, 2560])\n",
      "Patches Tensor Shape: torch.Size([221, 30])\n",
      "Word Embeddings Shape: torch.Size([5, 2560])\n"
     ]
    }
   ],
   "source": [
    "class Phi3Embedder:\n",
    "    def __init__(self, model_name=\"microsoft/phi-2\"):\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        self.model = AutoModel.from_pretrained(model_name)\n",
    "\n",
    "    def get_word_embeddings(self, words):\n",
    "        self.tokenizer.pad_token = self.tokenizer.eos_token\n",
    "        inputs = self.tokenizer(words, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "        print(\"Hidden size of model:\", self.model.config.hidden_size)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(**inputs)  # Output is (batch_size, seq_len, hidden_dim)\n",
    "        \n",
    "        # Use CLS token (first token) OR mean pooling\n",
    "        cls_embeddings = outputs.last_hidden_state[:, 0, :]  # (batch_size, embedding_dim)\n",
    "\n",
    "        print(\"Fixed Word Embeddings Shape:\", cls_embeddings.shape)  # Debugging\n",
    "        return cls_embeddings  # Should now be (num_words, 256)\n",
    "phi3 = Phi3Embedder()\n",
    "words = [\"growth\", \"volatility\", \"trend\", \"seasonality\", \"market\"]\n",
    "word_embeddings = phi3.get_word_embeddings(words)\n",
    "print(\"Patches Tensor Shape:\", patches_tensor.shape)  # Should be [221, 30]\n",
    "print(\"Word Embeddings Shape:\", word_embeddings.shape)  # Should be [5, 256]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Language Representation Shape: tensor([[ 0.0256, -0.1249,  0.0323,  ...,  0.0732,  0.4386, -0.0759],\n",
      "        [-0.1686,  0.1043,  0.0582,  ..., -0.1155, -0.0989, -0.1598],\n",
      "        [-0.0334,  0.1332, -0.1042,  ...,  0.0635, -0.1143,  0.2024],\n",
      "        [ 0.0538,  0.0452,  0.1771,  ...,  0.0335,  0.0884,  0.4106],\n",
      "        [ 0.1886, -0.1491,  0.1947,  ...,  0.1327,  0.1777,  0.2488]],\n",
      "       grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "class TimeSeriesToLanguage(nn.Module):\n",
    "    def __init__(self, input_dim, embed_dim, num_heads=4):\n",
    "        super().__init__()\n",
    "        self.patch_embedder = PatchEmbedder(input_dim, embed_dim)\n",
    "        self.text_linear = nn.Linear(embed_dim, embed_dim)\n",
    "        self.attention = nn.MultiheadAttention(embed_dim, num_heads)\n",
    "        self.output_linear = nn.Linear(embed_dim, embed_dim)\n",
    "\n",
    "    def forward(self, time_series_patches, text_embeddings):\n",
    "        time_series_embeddings = self.patch_embedder(time_series_patches)  \n",
    "        # Shape: (num_patches, embed_dim)\n",
    "        time_series_embeddings = time_series_embeddings.unsqueeze(1)  \n",
    "        # Shape: (num_patches, 1, embed_dim)\n",
    "        text_prototypes = self.text_linear(text_embeddings)  \n",
    "        # Shape: (num_words, embed_dim)\n",
    "        text_prototypes = text_prototypes.unsqueeze(1)  \n",
    "        # Shape: (num_words, 1, embed_dim)\n",
    "        # Ensure correct shape for MultiheadAttention\n",
    "        time_series_embeddings = time_series_embeddings.permute(1, 0, 2)  \n",
    "        # Shape: (1, num_patches, embed_dim)\n",
    "        text_prototypes = text_prototypes.permute(1, 0, 2)  \n",
    "        # Shape: (1, num_words, embed_dim)\n",
    "        # Ensure `seq_len` is the same for both\n",
    "        if time_series_embeddings.shape[1] != text_prototypes.shape[1]:\n",
    "            min_seq_len = min(time_series_embeddings.shape[1], text_prototypes.shape[1])\n",
    "            time_series_embeddings = time_series_embeddings[:, :min_seq_len, :]\n",
    "            text_prototypes = text_prototypes[:, :min_seq_len, :]\n",
    "\n",
    "        attn_output, _ = self.attention(time_series_embeddings, text_prototypes, text_prototypes)\n",
    "\n",
    "        return self.output_linear(attn_output.squeeze(0))  # (num_patches, embed_dim)\n",
    "model = TimeSeriesToLanguage(input_dim=30, embed_dim=2560)\n",
    "language_representation = model(patches_tensor, word_embeddings)\n",
    "\n",
    "print(\"Final Language Representation Shape:\", language_representation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:01<00:00,  1.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Text: Ġenc cern ĠClaw Ġdisaster Ġcommission\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "# Load Phi-2 tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/phi-2\")\n",
    "phi2_model = AutoModel.from_pretrained(\"microsoft/phi-2\")\n",
    "\n",
    "def decode_embeddings_to_words(embeddings, phi2_model, tokenizer):\n",
    "    \"\"\"\n",
    "    Convert model-generated embeddings into words by finding the closest tokens in Phi-2 vocabulary.\n",
    "    \"\"\"\n",
    "    with torch.no_grad():\n",
    "        # Get the token embeddings from Phi-2\n",
    "        token_embeddings = phi2_model.get_input_embeddings().weight  # (vocab_size, embed_dim)\n",
    "\n",
    "        # Compute cosine similarity\n",
    "        similarities = F.cosine_similarity(embeddings.unsqueeze(1), token_embeddings.unsqueeze(0), dim=-1)  \n",
    "        closest_tokens = similarities.argmax(dim=-1)  # Get index of the closest token\n",
    "\n",
    "        # Decode token IDs into words\n",
    "        decoded_words = tokenizer.convert_ids_to_tokens(closest_tokens.tolist())\n",
    "        \n",
    "    return \" \".join(decoded_words)\n",
    "\n",
    "# Convert the final language representation\n",
    "decoded_text = decode_embeddings_to_words(language_representation, phi2_model, tokenizer)\n",
    "\n",
    "print(\"Generated Text:\", decoded_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
